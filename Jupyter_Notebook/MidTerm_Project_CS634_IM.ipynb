{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# `**CS634-Data Mining Midterm Project**`\n",
        "\n",
        "**>Part 1**\n",
        "\n",
        "\n",
        "**Data Preparation and Pattern Generation**\n",
        "In this part, items for each retailer are defined and deterministic transactions are generated based on certain patterns. These patterns are not random and are designed to reflect the unique characteristics of each retailer. Here’s a brief explanation of the patterns used:\n",
        "\n",
        "  **•\tAmazon:** The pattern for Amazon is simply the index of the transaction modulo 10 plus 1. This means that the first transaction will contain the first item, the second transaction will contain the first two items, and so on, until the tenth transaction which will contain all ten items. After that, the pattern repeats.\n",
        "\n",
        "  **•\tWayfair:** The pattern for Wayfair is twice the index of the transaction plus 1, but not more than the total number of items. This means that the first transaction will contain the first item, the second transaction will contain the first three items, and so on.\n",
        "\n",
        "  **•\tWalmart:** The pattern for Walmart is twice the index of the transaction plus 2. This means that the first transaction will contain the first two items, the second transaction will contain the first four items, and so on.\n",
        "\n",
        "  **•\tBest Buy:** The pattern for Best Buy is a bit more complex. It involves finding the next prime number that is greater than the index of the transaction modulo the total number of items plus 1.\n",
        "  \n",
        "  **• Nike:** The pattern for Nike involves generating the Fibonacci sequence. The index of the transaction plus 1 is used to find the corresponding number in the Fibonacci sequence, and this number determines the number of items in the transaction.\n",
        "\n",
        "The transactions are then saved in CSV files for further processing. This stage is crucial as it sets up the data that will be used for the rest of the project. The deterministic nature of these transactions, as specified in the project details, allows for consistent and meaningful analysis in the subsequent stages.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "JBak0d8VsrtI"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3id5XdqgU05"
      },
      "source": [
        "**Install pyfpgrowth using the code below**\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyfpgrowth"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "antiuA4Qs8uO",
        "outputId": "7d6d3bc2-926a-4af0-ba14-1aaf4e01f1e3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyfpgrowth in /usr/local/lib/python3.10/dist-packages (1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from mlxtend.frequent_patterns import apriori, association_rules\n",
        "import pyfpgrowth\n",
        "import itertools\n",
        "import time\n",
        "from itertools import combinations"
      ],
      "metadata": {
        "id": "8MM_E2_Cs-h5"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "8oyfbDJu3anf"
      },
      "outputs": [],
      "source": [
        "# List of items for each retailer\n",
        "amazon_items = ['Kindle E-reader', 'Echo Dot (4th Gen)', 'Fire TV Stick 4K', 'Microfiber Sheet Set', 'Portable Wireless Bluetooth Speaker', 'Stainless Steel Electric Kettle', 'High-Speed HDMI Cable', 'Silicone Baking Mat Sheet', 'AAA Performance Alkaline Batteries', 'Quick-Dry Bath Towels']\n",
        "wayfair_items = ['Wayfair Basics 1800 Series Sheet Set', 'Amherst Upholstered Platform Bed', 'Landen Hand-Tufted Silver/Ivory Area Rug', 'Kearney Sectional', 'Gold Flamingo Anna Maria Desk', 'Three Posts Teen Northampt Reversible Quilt Set', 'Mercury Row Wiersma End Table', 'Andover Mills Liesel Comforter Set', 'Greyleigh Dorset Ivory/Fuchsia Indoor Area Rug', 'Zipcode Design Folkston Desk']\n",
        "walmart_items = ['Mainstays Microfiber Sheet Set', 'Great Value LED Light Bulb', 'Ozark Trail Camping Chair', 'Equate Hand Sanitizer', 'Parents Choice Diapers', 'Onn. Full-Motion Articulating TV Wall Mount', 'Athletic Works Womens Active Core Legging', 'George Mens Regular Fit Jean', 'Mainstays 71\" 5-Shelf Bookcase', 'Hyper Tough 20V Max Cordless Drill']\n",
        "bestbuy_items = ['Insignia™ - 50\" Class F30 Series LED 4K UHD Smart Fire TV', 'Apple - AirPods Pro', 'Samsung - Galaxy S21 5G', 'HP - ENVY x360 2-in-1 15.6\" Touch-Screen Laptop', 'Sony - PlayStation 5 Console', 'Ring - Video Doorbell 3', 'JBL - Flip 5 Portable Bluetooth Speaker', 'Canon - EOS Rebel T7 DSLR Video Camera', 'WD - Easystore 5TB External USB 3.0 Portable Hard Drive', 'Keurig - K-Classic K50 Single Serve K-Cup Pod Coffee Maker']\n",
        "nike_items = ['Nike Air Force 1 07', 'Nike Sportswear Club Fleece', 'Nike Dri-FIT Academy', 'Nike Air Zoom Pegasus 38', 'Nike Sportswear Essential', 'Nike Pro', 'Nike Air Max 270', 'Nike Mercurial Superfly 8 Elite FG', 'Nike Yoga Dri-FIT', 'Nike SB Zoom Stefan Janoski RM']\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dictionary of items for each retailer\n",
        "retailers_items = {\n",
        "    'amazon': amazon_items,\n",
        "    'wayfair': wayfair_items,\n",
        "    'walmart': walmart_items,\n",
        "    'bestbuy': bestbuy_items,\n",
        "    'nike': nike_items\n",
        "}\n",
        "def is_prime(n):\n",
        "    if n <= 1:\n",
        "        return False\n",
        "    if n <= 3:\n",
        "        return True\n",
        "    if n % 2 == 0 or n % 3 == 0:\n",
        "        return False\n",
        "    i = 5\n",
        "    while i * i <= n:\n",
        "        if n % i == 0 or n % (i + 2) == 0:\n",
        "            return False\n",
        "        i += 6\n",
        "    return True\n",
        "\n",
        "def fibonacci(n):\n",
        "    if n <= 0:\n",
        "        return 0\n",
        "    elif n == 1:\n",
        "        return 1\n",
        "    else:\n",
        "        a, b = 0, 1\n",
        "        for _ in range(n - 1):\n",
        "            a, b = b, a + b\n",
        "        return b\n",
        "\n",
        "# Patterns for each retailer\n",
        "patterns = {\n",
        "    'amazon': lambda i, _: i % 10 + 1,\n",
        "    'wayfair': lambda i, _: 2 * i + 1 if 2 * i + 1 <= len(retailers_items['wayfair']) else 1,\n",
        "    'walmart': lambda i, _: 2 * (i + 1),\n",
        "    'bestbuy': lambda i, num_items: next((x for x in range(i % num_items + 1, num_items + 1) if is_prime(x)), 1),\n",
        "    'nike': lambda i, _: fibonacci(i + 1) if fibonacci(i + 1) <= len(retailers_items['nike']) else 1\n",
        "}\n",
        "\n",
        "def generate_deterministic_transactions(retailer, num_transactions):\n",
        "    if retailer not in retailers_items or retailer not in patterns:\n",
        "        print(f\"No items or pattern found for retailer: {retailer}\")\n",
        "        return\n",
        "\n",
        "    transactions = []\n",
        "    for i in range(num_transactions):\n",
        "        num_items = patterns[retailer](i, len(retailers_items[retailer]))  # Apply the retailer's pattern to determine the number of items\n",
        "        transaction = retailers_items[retailer][:num_items]  # Select the first 'num_items' from the list\n",
        "        transactions.append(\", \".join(transaction))\n",
        "\n",
        "    return pd.DataFrame({'Transaction ID': [f'Trans{i+1}' for i in range(num_transactions)],\n",
        "                         f'{retailer.capitalize()} Transaction': transactions})\n",
        "\n",
        "# Generate sample transactions for each retailer\n",
        "for retailer in retailers_items.keys():\n",
        "    transactions = generate_deterministic_transactions(retailer, 20)\n",
        "    transactions.to_csv(f'{retailer}_transactions.csv', index=False)\n",
        "    print(f\"Generated transactions for {retailer} and saved to {retailer}_transactions.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bi-y5yOtv9Dl",
        "outputId": "422f7e44-1aa3-4526-bd70-644dff17975b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated transactions for amazon and saved to amazon_transactions.csv\n",
            "Generated transactions for wayfair and saved to wayfair_transactions.csv\n",
            "Generated transactions for walmart and saved to walmart_transactions.csv\n",
            "Generated transactions for bestbuy and saved to bestbuy_transactions.csv\n",
            "Generated transactions for nike and saved to nike_transactions.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4XAi7xHcQf5"
      },
      "source": [
        "**Project Part 2**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading Transactions**\n",
        "\n",
        "In this stage, the transactions from the CSV files are loaded into a DataFrame. This is important because the subsequent analysis requires the data to be in a specific format (a DataFrame).\n",
        "\n",
        "\n",
        "**Frequent Itemset Generation**\n",
        "\n",
        "This is the core of the project. In this stage, three different methods (brute force, Apriori, and FP-Growth) are implemented to generate frequent itemsets from the transactions. Frequent itemsets are sets of items that appear together in the transactions more often than a specified minimum number of times (the support level). This stage is crucial for understanding the relationships between different items.\n",
        "\n",
        "**Association Rule Mining**\n",
        "\n",
        "After generating the frequent itemsets, they are used to generate association rules. These rules can tell that if certain items are bought together, it’s likely that another item will be bought as well. This is useful for making recommendations to customers.\n",
        "\n",
        "**Performance Comparison**\n",
        "In the final stage, the performance of the three methods used for generating frequent itemsets is compared. This can help understand which method is the most efficient for the data."
      ],
      "metadata": {
        "id": "OMrTURmnXAPk"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_f2yMSlcXAJ"
      },
      "source": [
        "####**Prompt the user for the minimum support and confidence levels**\n",
        "\n",
        "#### **Prompt the user to choose a Database**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prompt the user for the minimum support level\n",
        "while True:\n",
        "    min_support = float(input(\"Enter the minimum support level (between 0 and 1): \"))\n",
        "    if 0 <= min_support <= 1:\n",
        "        break\n",
        "    else:\n",
        "        print(\"Invalid input. Please enter a number between 0 and 1.\")\n",
        "\n",
        "# Prompt the user for the minimum confidence level\n",
        "while True:\n",
        "    min_confidence = float(input(\"Enter the minimum confidence level (between 0 and 1): \"))\n",
        "    if 0 <= min_confidence <= 1:\n",
        "        break\n",
        "    else:\n",
        "        print(\"Invalid input. Please enter a number between 0 and 1.\")\n",
        "\n",
        "# Prompt the user to choose a database\n",
        "database_choice = input(\"Which database would you like to analyze? Enter '1' for Amazon, '2' for Best Buy, '3' for WayFair, '4' for WalMart, or '5' for Nike: \")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2DLgCeQjUyU",
        "outputId": "23a6a9c4-164b-4df6-b0e5-3574e15661a8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter the minimum support level (between 0 and 1): 0.5\n",
            "Enter the minimum confidence level (between 0 and 1): 0.6\n",
            "Which database would you like to analyze? Enter '1' for Amazon, '2' for Best Buy, '3' for WayFair, '4' for WalMart, or '5' for Nike: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55lwvn3dhRHQ"
      },
      "source": [
        "**Define Brute-Force method**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the transactions from the CSV files\n",
        "def load_transactions_from_csv(database_choice):\n",
        "    if database_choice == '1':\n",
        "        transactions = pd.read_csv('amazon_transactions.csv')\n",
        "    elif database_choice == '2':\n",
        "        transactions = pd.read_csv('bestbuy_transactions.csv')\n",
        "    elif database_choice == '3':\n",
        "        transactions = pd.read_csv('wayfair_transactions.csv')\n",
        "    elif database_choice == '4':\n",
        "        transactions = pd.read_csv('walmart_transactions.csv')\n",
        "    elif database_choice == '5':\n",
        "        transactions = pd.read_csv('nike_transactions.csv')\n",
        "    else:\n",
        "        print(\"Invalid choice. Please enter a number between 1 and 5.\")\n",
        "        return None\n",
        "    return transactions"
      ],
      "metadata": {
        "id": "k1miNi7ajLxa"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to generate frequent itemsets using brute force\n",
        "def generate_frequent_itemsets_brute_force(transactions, min_support):\n",
        "    # Flatten the list of transactions and find unique items\n",
        "    items = list(set(x for sublist in transactions for x in sublist))\n",
        "\n",
        "    # Define a list to hold the frequent itemsets\n",
        "    frequent_itemsets = []\n",
        "\n",
        "    # Generate all possible itemsets up to the length of items\n",
        "    for r in range(1, len(items) + 1):\n",
        "        # Use combinations to generate itemsets of length r\n",
        "        for itemset in combinations(items, r):\n",
        "            # Count the support for the itemset\n",
        "            support = sum(1 for transaction in transactions if set(itemset).issubset(transaction))\n",
        "            # If the support is greater than or equal to the min_support, add it to the list of frequent itemsets\n",
        "            if support / len(transactions) >= min_support:\n",
        "                frequent_itemsets.append(itemset)\n",
        "\n",
        "    return frequent_itemsets"
      ],
      "metadata": {
        "id": "3RVrAGRc4I2l"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAKqHk19bWeB"
      },
      "source": [
        "**Step 5: Implement the brute force method, Apriori and FP Growth algorithm with the user specified support level to generate frequent items and generate association rules**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to calculate the support of an itemset\n",
        "def calculate_support(itemset, transactions):\n",
        "    count = sum(1 for transaction in transactions if set(itemset).issubset(transaction))\n",
        "    return count / len(transactions)\n",
        "\n",
        "# Load the chosen dataset\n",
        "df_transactions = load_transactions_from_csv(database_choice)\n",
        "\n",
        "# Convert transactions into a list of item lists\n",
        "transactions = [transaction.split(', ') for transaction in df_transactions['Bestbuy Transaction']]\n",
        "\n",
        "# Generate frequent itemsets using the brute force method\n",
        "start_time = time.time()  # Add this line to record the start time\n",
        "brute_force_itemsets = generate_frequent_itemsets_brute_force(transactions, min_support)\n",
        "brute_force_time = time.time() - start_time  # Add this line to calculate the execution time\n",
        "\n",
        "if not brute_force_itemsets:\n",
        "    print(\"No frequent itemsets met the minimum support level using the brute force method.\")\n",
        "else:\n",
        "    # Convert frequent itemsets to itemsets and support values\n",
        "    itemsets = [tuple(itemset) for itemset in brute_force_itemsets]\n",
        "    supports = [calculate_support(itemset, transactions) for itemset in brute_force_itemsets]\n",
        "\n",
        "    # Create a new DataFrame with itemsets and support columns\n",
        "    rules_df = pd.DataFrame({'itemsets': itemsets, 'support': supports})\n",
        "\n",
        "    # Generate association rules from the new DataFrame if it's not empty\n",
        "    if not rules_df.empty:\n",
        "        brute_force_rules = association_rules(rules_df, metric=\"confidence\", min_threshold=min_confidence, support_only=True)\n",
        "\n",
        "        # Print the association rules\n",
        "        if not brute_force_rules.empty:\n",
        "            print(\"\\nBrute Force Association Rules:\")\n",
        "            print(brute_force_rules)\n",
        "        else:\n",
        "            print(\"No association rules met the minimum confidence level using the brute force method.\")\n",
        "    else:\n",
        "        print(\"No frequent itemsets found. Unable to generate association rules using the brute force method.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kqqqo-hF-Q71",
        "outputId": "a963a8c5-2ea7-43d5-aa57-8e9e2574f49e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Brute Force Association Rules:\n",
            "                                         antecedents  \\\n",
            "0                              (Apple - AirPods Pro)   \n",
            "1  (Insignia™ - 50\" Class F30 Series LED 4K UHD S...   \n",
            "\n",
            "                                         consequents  antecedent support  \\\n",
            "0  (Insignia™ - 50\" Class F30 Series LED 4K UHD S...                 NaN   \n",
            "1                              (Apple - AirPods Pro)                 NaN   \n",
            "\n",
            "   consequent support  support  confidence  lift  leverage  conviction  \\\n",
            "0                 NaN      0.7         NaN   NaN       NaN         NaN   \n",
            "1                 NaN      0.7         NaN   NaN       NaN         NaN   \n",
            "\n",
            "   zhangs_metric  \n",
            "0            NaN  \n",
            "1            NaN  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyfpgrowth import find_frequent_patterns, generate_association_rules\n",
        "from mlxtend.frequent_patterns import apriori\n",
        "\n",
        "##For Apriori\n",
        "# Convert transactions into a list of item lists\n",
        "transactions_list = [transaction.split(', ') for transaction in df_transactions['Bestbuy Transaction']]\n",
        "\n",
        "# Generate the list of unique items\n",
        "items = sorted(set(item for transaction in transactions_list for item in transaction))\n",
        "\n",
        "# Convert transactions into a one-hot encoded DataFrame\n",
        "df = pd.DataFrame([[item in transaction for item in items] for transaction in transactions_list], columns=items)\n",
        "\n",
        "# Generate frequent itemsets using the Apriori method\n",
        "start_time = time.time()\n",
        "apriori_itemsets = apriori(df, min_support=min_support, use_colnames=True)\n",
        "apriori_time = time.time() - start_time\n",
        "\n",
        "##For FP_Growth\n",
        "# Convert transactions into a list of item lists\n",
        "transactions_list = [transaction.split(', ') for transaction in df_transactions['Bestbuy Transaction']]\n",
        "\n",
        "# Convert min_support from a fraction to a count\n",
        "min_support_count = int(min_support * len(transactions_list))\n",
        "\n",
        "# Find frequent patterns using FP-Growth\n",
        "start_time = time.time()\n",
        "patterns = find_frequent_patterns(transactions_list, min_support_count)\n",
        "fpgrowth_time = time.time() - start_time\n",
        "\n",
        "if not apriori_itemsets.empty:\n",
        "    # Generate association rules from the frequent itemsets\n",
        "    apriori_rules = association_rules(apriori_itemsets, metric=\"confidence\", min_threshold=min_confidence)\n",
        "    if not apriori_rules.empty:\n",
        "        print(\"\\nApriori Association Rules:\")\n",
        "        print(apriori_rules)\n",
        "    else:\n",
        "        print(\"No association rules met the minimum confidence level using the Apriori method.\")\n",
        "else:\n",
        "    print(\"No frequent itemsets met the minimum support level using the Apriori method.\")\n",
        "\n",
        "# For FP-Growth\n",
        "if patterns:\n",
        "    fpgrowth_rules = generate_association_rules(patterns, min_confidence)\n",
        "    if fpgrowth_rules:\n",
        "        print(\"\\nFP-Growth Association Rules:\")\n",
        "        print(fpgrowth_rules)  # Print the fpgrowth_rules to inspect its structure\n",
        "    else:\n",
        "        print(\"No association rules met the minimum confidence level using the FP-Growth method.\")\n",
        "else:\n",
        "    print(\"No frequent patterns met the minimum support level using the FP-Growth method.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z9Bs7g0zFcI-",
        "outputId": "5bf4c4fe-fca5-47de-d6d4-e37644fcef60"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Apriori Association Rules:\n",
            "                                         antecedents  \\\n",
            "0                              (Apple - AirPods Pro)   \n",
            "1  (Insignia™ - 50\" Class F30 Series LED 4K UHD S...   \n",
            "2                          (Samsung - Galaxy S21 5G)   \n",
            "3                              (Apple - AirPods Pro)   \n",
            "4                          (Samsung - Galaxy S21 5G)   \n",
            "5     (Samsung - Galaxy S21 5G, Apple - AirPods Pro)   \n",
            "6  (Samsung - Galaxy S21 5G, Insignia™ - 50\" Clas...   \n",
            "7  (Apple - AirPods Pro, Insignia™ - 50\" Class F3...   \n",
            "8                          (Samsung - Galaxy S21 5G)   \n",
            "9                              (Apple - AirPods Pro)   \n",
            "\n",
            "                                         consequents  antecedent support  \\\n",
            "0  (Insignia™ - 50\" Class F30 Series LED 4K UHD S...                 0.7   \n",
            "1                              (Apple - AirPods Pro)                 1.0   \n",
            "2                              (Apple - AirPods Pro)                 0.5   \n",
            "3                          (Samsung - Galaxy S21 5G)                 0.7   \n",
            "4  (Insignia™ - 50\" Class F30 Series LED 4K UHD S...                 0.5   \n",
            "5  (Insignia™ - 50\" Class F30 Series LED 4K UHD S...                 0.5   \n",
            "6                              (Apple - AirPods Pro)                 0.5   \n",
            "7                          (Samsung - Galaxy S21 5G)                 0.7   \n",
            "8  (Apple - AirPods Pro, Insignia™ - 50\" Class F3...                 0.5   \n",
            "9  (Samsung - Galaxy S21 5G, Insignia™ - 50\" Clas...                 0.7   \n",
            "\n",
            "   consequent support  support  confidence      lift  leverage  conviction  \\\n",
            "0                 1.0      0.7    1.000000  1.000000      0.00         inf   \n",
            "1                 0.7      0.7    0.700000  1.000000      0.00        1.00   \n",
            "2                 0.7      0.5    1.000000  1.428571      0.15         inf   \n",
            "3                 0.5      0.5    0.714286  1.428571      0.15        1.75   \n",
            "4                 1.0      0.5    1.000000  1.000000      0.00         inf   \n",
            "5                 1.0      0.5    1.000000  1.000000      0.00         inf   \n",
            "6                 0.7      0.5    1.000000  1.428571      0.15         inf   \n",
            "7                 0.5      0.5    0.714286  1.428571      0.15        1.75   \n",
            "8                 0.7      0.5    1.000000  1.428571      0.15         inf   \n",
            "9                 0.5      0.5    0.714286  1.428571      0.15        1.75   \n",
            "\n",
            "   zhangs_metric  \n",
            "0            0.0  \n",
            "1            0.0  \n",
            "2            0.6  \n",
            "3            1.0  \n",
            "4            0.0  \n",
            "5            0.0  \n",
            "6            0.6  \n",
            "7            1.0  \n",
            "8            0.6  \n",
            "9            1.0  \n",
            "\n",
            "FP-Growth Association Rules:\n",
            "{('Apple - AirPods Pro',): (('Insignia™ - 50\" Class F30 Series LED 4K UHD Smart Fire TV', 'Samsung - Galaxy S21 5G'), 0.7142857142857143), ('Insignia™ - 50\" Class F30 Series LED 4K UHD Smart Fire TV',): (('Apple - AirPods Pro',), 0.7), ('Samsung - Galaxy S21 5G',): (('Apple - AirPods Pro', 'Insignia™ - 50\" Class F30 Series LED 4K UHD Smart Fire TV'), 1.0), ('Apple - AirPods Pro', 'Insignia™ - 50\" Class F30 Series LED 4K UHD Smart Fire TV'): (('Samsung - Galaxy S21 5G',), 0.7142857142857143), ('Apple - AirPods Pro', 'Samsung - Galaxy S21 5G'): (('Insignia™ - 50\" Class F30 Series LED 4K UHD Smart Fire TV',), 1.0), ('Insignia™ - 50\" Class F30 Series LED 4K UHD Smart Fire TV', 'Samsung - Galaxy S21 5G'): (('Apple - AirPods Pro',), 1.0)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Finally: Performance Comparison**"
      ],
      "metadata": {
        "id": "VpdRmAZtZW7M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare the results from the three methods\n",
        "def compare_results(brute_force_rules, apriori_rules, fpgrowth_rules):\n",
        "    print(\"Brute Force Rules:\")\n",
        "    if not brute_force_rules.empty:\n",
        "        print(brute_force_rules)\n",
        "    else:\n",
        "        print(\"No association rules found using the brute force method.\")\n",
        "\n",
        "    print(\"\\nApriori Rules:\")\n",
        "    if not apriori_rules.empty:\n",
        "        print(apriori_rules)\n",
        "    else:\n",
        "        print(\"No association rules found using the Apriori method.\")\n",
        "\n",
        "    print(\"\\nFP-Growth Rules:\")\n",
        "    if fpgrowth_rules:\n",
        "        print(fpgrowth_rules)\n",
        "    else:\n",
        "        print(\"No association rules found using the FP-Growth method.\")\n",
        "\n",
        "# Print the time taken by each method\n",
        "print(\"\\nTime taken by brute force method: \", brute_force_time)\n",
        "print(\"Time taken by Apriori: \", apriori_time)\n",
        "print(\"Time taken by FP-Growth: \", fpgrowth_time)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRdDrE3rB-JA",
        "outputId": "921e0a16-807a-4a59-b8a1-d6d258997085"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Time taken by brute force method:  0.002124309539794922\n",
            "Time taken by Apriori:  0.010610103607177734\n",
            "Time taken by FP-Growth:  0.0003476142883300781\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
      ],
      "metadata": {
        "id": "8NDEiItFd6zj"
      },
      "execution_count": 5,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}